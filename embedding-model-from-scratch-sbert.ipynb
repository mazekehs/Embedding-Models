{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading Dataset\n\n****The Multi-Genre Natural Language Inference (MNLI) corpus,\nwhich is a collection of 392,702 sentence pairs annotated with entailment (contradic‐\ntion, neutral, entailment). We will be using a subset of the data, 50,000 annotated\nsentence pairs, to create a minimal example that does not need to be trained for hours\non end.****","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-10T19:14:41.634287Z","iopub.execute_input":"2024-11-10T19:14:41.634705Z","iopub.status.idle":"2024-11-10T19:14:42.866265Z","shell.execute_reply.started":"2024-11-10T19:14:41.634662Z","shell.execute_reply":"2024-11-10T19:14:42.865230Z"}}},{"cell_type":"code","source":"from datasets import load_dataset\n# Loading MNLI dataset from GLUE\n# 0 = entailment, 1 = neutral, 2 = contradiction\ntrain_dataset = load_dataset(\n \"glue\", \"mnli\", split=\"train\"\n).select(range(50_000))\ntrain_dataset = train_dataset.remove_columns(\"idx\")","metadata":{"execution":{"iopub.status.busy":"2024-11-10T19:47:36.675063Z","iopub.execute_input":"2024-11-10T19:47:36.675435Z","iopub.status.idle":"2024-11-10T19:47:44.901950Z","shell.execute_reply.started":"2024-11-10T19:47:36.675399Z","shell.execute_reply":"2024-11-10T19:47:44.901061Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/35.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89a6db96e39e4e6fbe4461cd50a29137"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/52.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37f1d8ccfe52422d8b20227866cf8a28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)alidation_matched-00000-of-00001.parquet:   0%|          | 0.00/1.21M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ebd4e38611b43ccbbe83db2709ebaf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)dation_mismatched-00000-of-00001.parquet:   0%|          | 0.00/1.25M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff149f8f64b4440d975a624e278699f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test_matched-00000-of-00001.parquet:   0%|          | 0.00/1.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c49b7d0b24c54e5fbbede0bbba3ae951"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test_mismatched-00000-of-00001.parquet:   0%|          | 0.00/1.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"362d0e3d3cff4857b1081acfbda5ce45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50ffaf876ec64e9e9e0144ad5f3453d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"939b4128262243758c7032bfc5ad0037"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b0090e53dca49a0ba91d1114bb2a1e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_matched split:   0%|          | 0/9796 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7afbca8275c4642a9290d379dc64f55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_mismatched split:   0%|          | 0/9847 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1bcb4658a8645b4b37d367da38654d3"}},"metadata":{}}]},{"cell_type":"code","source":"print(train_dataset[3])\nprint(train_dataset[6])","metadata":{"execution":{"iopub.status.busy":"2024-11-10T19:47:46.947403Z","iopub.execute_input":"2024-11-10T19:47:46.948390Z","iopub.status.idle":"2024-11-10T19:47:46.955944Z","shell.execute_reply.started":"2024-11-10T19:47:46.948348Z","shell.execute_reply":"2024-11-10T19:47:46.954923Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"{'premise': 'How do you know? All this is their information again.', 'hypothesis': 'This information belongs to them.', 'label': 0}\n{'premise': 'But a few Christian mosaics survive above the apse is the Virgin with the infant Jesus, with the Archangel Gabriel to the right (his companion Michael, to the left, has vanished save for a few feathers from his wings).', 'hypothesis': 'Most of the Christian mosaics were destroyed by Muslims.  ', 'label': 1}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training the model \n\n**We typically choose an existing sentence-transformers model\nand fine-tune that model, but in this example, we are going to train an embedding\nfrom scratch.\nThis means that we will have to define two things. First, a pretrained Transformer\nmodel that serves as embedding individual words. We will use the BERT base model\n(uncased) as it is a great introduction model.**","metadata":{}},{"cell_type":"code","source":"!pip install sentence_transformers\nfrom sentence_transformers import SentenceTransformer\n# Using a base model\nembedding_model = SentenceTransformer('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-11-10T19:47:49.029265Z","iopub.execute_input":"2024-11-10T19:47:49.029648Z","iopub.status.idle":"2024-11-10T19:48:23.881138Z","shell.execute_reply.started":"2024-11-10T19:47:49.029612Z","shell.execute_reply":"2024-11-10T19:48:23.880279Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.8/255.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-3.2.1\n","output_type":"stream"},{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7646b75c0d334c4a9d72f24c2791815f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1175c2a033ac498c8637c4becee82333"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f31a99f4d9174b1eb5ed0a669c13312e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50be4c40f05d4fc684926d4a8c093cc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28c71d9dfbae4ccaa4cfaad0e0fb6ed2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e5b9e8731ed408da7a77d2d33433d27"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Loss Function to optimize the model","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import losses\n#softmax loss\ntrain_loss = losses.SoftmaxLoss(\n model=embedding_model,\n sentence_embedding_dimension=embedding_model.get_sentence_embedding_dimension(), num_labels=3)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T19:48:23.882865Z","iopub.execute_input":"2024-11-10T19:48:23.883473Z","iopub.status.idle":"2024-11-10T19:48:23.900167Z","shell.execute_reply.started":"2024-11-10T19:48:23.883438Z","shell.execute_reply":"2024-11-10T19:48:23.899387Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation\n\n**We can perform evaluation of the performance of our model using the Semantic\nTextual Similarity Benchmark (STSB). It is a collection of human-labeled sentence\npairs, with similarity scores between 1 and 5.**","metadata":{}},{"cell_type":"code","source":"from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n# Creating an embedding similarity evaluator for STSB\nval_sts = load_dataset(\"glue\", \"stsb\", split=\"validation\")\nevaluator = EmbeddingSimilarityEvaluator(\n sentences1=val_sts[\"sentence1\"],\n sentences2=val_sts[\"sentence2\"],\n scores=[score/5 for score in val_sts[\"label\"]],\n main_similarity=\"cosine\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T19:48:26.909388Z","iopub.execute_input":"2024-11-10T19:48:26.910148Z","iopub.status.idle":"2024-11-10T19:48:30.415582Z","shell.execute_reply.started":"2024-11-10T19:48:26.910108Z","shell.execute_reply":"2024-11-10T19:48:30.414170Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/502k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fe81e852cb04184bc1421df580989f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/151k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fd81792f56643c0b8c9aa2bdae53723"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/114k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f6ad95bba014f5b8e199b4200f0b3d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f66bdf3a60245d49ac2aaa92fbbe944"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bae35b7d5d4247dabbf16e481a09d063"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e7fe76330c0401cb51f9392d2d03863"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Defining the training arguements\n\n**we have our evaluator, we create SentenceTransformerTrainingArgu\nments, similar to training with Hugging Face Transformers**","metadata":{}},{"cell_type":"code","source":"from sentence_transformers.training_args import SentenceTransformerTrainingArguments","metadata":{"execution":{"iopub.status.busy":"2024-11-10T19:48:35.651396Z","iopub.execute_input":"2024-11-10T19:48:35.652016Z","iopub.status.idle":"2024-11-10T19:48:35.656350Z","shell.execute_reply.started":"2024-11-10T19:48:35.651975Z","shell.execute_reply":"2024-11-10T19:48:35.655498Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"args = SentenceTransformerTrainingArguments(\n output_dir=\"base_embedding_model\",\n num_train_epochs=1,\n per_device_train_batch_size=32,\n per_device_eval_batch_size=32,\n warmup_steps=100,\n fp16=True,\n eval_steps=100,\n logging_steps=100,\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T19:48:38.180436Z","iopub.execute_input":"2024-11-10T19:48:38.181309Z","iopub.status.idle":"2024-11-10T19:48:38.210515Z","shell.execute_reply.started":"2024-11-10T19:48:38.181266Z","shell.execute_reply":"2024-11-10T19:48:38.209767Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Training the embedding model","metadata":{}},{"cell_type":"code","source":"from sentence_transformers.trainer import SentenceTransformerTrainer\n# Training\ntrainer = SentenceTransformerTrainer(\n model=embedding_model,\n args=args,\n train_dataset=train_dataset,\n loss=train_loss,\n evaluator=evaluator\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-11-10T19:48:40.436425Z","iopub.execute_input":"2024-11-10T19:48:40.437398Z","iopub.status.idle":"2024-11-10T19:57:43.125431Z","shell.execute_reply.started":"2024-11-10T19:48:40.437357Z","shell.execute_reply":"2024-11-10T19:57:43.124638Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113403911111971, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b159ceb3caa487c9d3723fd9dc4cdc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241110_194901-2q12kxc8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/abhishekkumar23951-nit-durgapur/sentence-transformers/runs/2q12kxc8' target=\"_blank\">base_embedding_model</a></strong> to <a href='https://wandb.ai/abhishekkumar23951-nit-durgapur/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/abhishekkumar23951-nit-durgapur/sentence-transformers' target=\"_blank\">https://wandb.ai/abhishekkumar23951-nit-durgapur/sentence-transformers</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/abhishekkumar23951-nit-durgapur/sentence-transformers/runs/2q12kxc8' target=\"_blank\">https://wandb.ai/abhishekkumar23951-nit-durgapur/sentence-transformers/runs/2q12kxc8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1563/1563 08:37, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>1.079800</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.934000</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.877300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.841000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.827900</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.823600</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.800200</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.789000</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.774800</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.771800</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.750200</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.733700</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.744700</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.716100</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.752700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1563, training_loss=0.8113608772146038, metrics={'train_runtime': 539.8233, 'train_samples_per_second': 92.623, 'train_steps_per_second': 2.895, 'total_flos': 0.0, 'train_loss': 0.8113608772146038, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Evaluating Results","metadata":{}},{"cell_type":"code","source":"# Evaluating our trained model\nresult=evaluator(embedding_model)\nresult","metadata":{"execution":{"iopub.status.busy":"2024-11-10T20:01:58.881763Z","iopub.execute_input":"2024-11-10T20:01:58.882115Z","iopub.status.idle":"2024-11-10T20:02:02.219744Z","shell.execute_reply.started":"2024-11-10T20:01:58.882082Z","shell.execute_reply":"2024-11-10T20:02:02.218754Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'pearson_cosine': 0.5345397045887939,\n 'spearman_cosine': 0.6082469138789448,\n 'pearson_manhattan': 0.5801962729306847,\n 'spearman_manhattan': 0.6068780695191375,\n 'pearson_euclidean': 0.571048137696305,\n 'spearman_euclidean': 0.6029259030941507,\n 'pearson_dot': 0.5044776644612751,\n 'spearman_dot': 0.5443529748240566,\n 'pearson_max': 0.5801962729306847,\n 'spearman_max': 0.6082469138789448}"},"metadata":{}}]},{"cell_type":"code","source":"print(result['pearson_cosine'])","metadata":{"execution":{"iopub.status.busy":"2024-11-10T20:03:49.361451Z","iopub.execute_input":"2024-11-10T20:03:49.362128Z","iopub.status.idle":"2024-11-10T20:03:49.368250Z","shell.execute_reply.started":"2024-11-10T20:03:49.362090Z","shell.execute_reply":"2024-11-10T20:03:49.367240Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"0.5345397045887939\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}